# Default configuration for recommender system

# Model configuration
model:
  type: "catboost"
  config:
    catboost:
      iterations: 500
      learning_rate: 0.1
      depth: 6
      l2_leaf_reg: 3.0
      verbose: 100
      loss_function: "Logloss"
      eval_metric: "AUC"
      early_stopping_rounds: 50

# Features
features:
  - "count_purchase_user_product"
  - "count_purchase_user_store"
  - "ctr_product"
  - "recency_user_product"
  - "user_stats"
  - "product_stats"
  - "store_stats"
  - "city_stats"
  - "product_temporal_patterns"
  # - "recency_user_store"
  # - "time_features"
  # - "time_window_user_product"
  # - "session_features"
  # - "frequency_features"
  # - "product_popularity_trend"
  # - "cross_features"
  # - "user_segments"
  # - "memory-based-cf"       # Collaborative filtering
  # - "npmi-cf"               # Collaborative filtering
  # - "puresvd-cf"            # Collaborative filtering
  # - "svd-cf"                # Collaborative filtering
  # - "product_embeddings"    # NLP feature
  # - "category_embeddings"   # NLP faturee

# Target definition
target: "CartUpdate_Purchase_vs_View"

# Data paths
data:
  train_path: "data/train.parquet"
  test_path: "data/test.parquet"
  sample_size: null  # Set to a number for debugging (e.g., 10000)

# Training configuration for full history approach
training:
  target_days: 7       # Target window is 7 days (increased to better match test window size)
  step_days: 7         # Move window 7 days at a time
  max_splits: 10       # Use more sliding windows to capture more patterns
  validation_days: 7   # Use 7 days after target window for validation

# Kaggle test simulation configuration
kaggle_simulation:
  test_days: 30        # Last 30 days reserved for testing (simulating Kaggle test set)
  train_days: 30       # Days before test period used for training
  validation_ratio: 0.2  # Portion of training data to use for validation

# Text processing configuration
text_processing:
  model_type: "sentence-transformers"
  model_name: "paraphrase-multilingual-MiniLM-L12-v2"  # Small but effective model
  embedding_dimensions: 20  # Reduce dimensionality for efficiency

# Output settings
output:
  results_dir: "results"
  save_model: true
  save_predictions: true
  save_evaluation_results: true  # Save Kaggle simulation evaluation results

# History cleaning
history_cleaning:
  remove_lurkers: true

# Logging configuration
logging:
  console_level: "INFO"
  file_level: "DEBUG"
  file: "lavka_recsys.log"

# Optional preprocessing
preprocessing:
  normalize_timestamps: true

# Feature selection
feature_selection:
  enabled: false
  method: "importance"
  # threshold: 0.05
  n_features: 20